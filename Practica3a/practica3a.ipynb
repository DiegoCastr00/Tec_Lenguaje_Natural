{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Daphne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Daphne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Daphne\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "import numpy as np\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocesar(texto):\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    words = word_tokenize(texto)\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    ps = PorterStemmer()\n",
    "    words = [ps.stem(word) for word in words]\n",
    "    return ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_personalidad(texto):\n",
    "    texto_procesado = preprocesar(texto)\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform([texto_procesado])\n",
    "    \n",
    "    openness = np.random.rand()\n",
    "    conscientiousness = np.random.rand()\n",
    "    extraversion = np.random.rand()\n",
    "    agreeableness = np.random.rand()\n",
    "    neuroroticism = np.random.rand()\n",
    "    \n",
    "    return {\n",
    "        'openness': openness,\n",
    "        'conscientiousness' :conscientiousness,\n",
    "        'extraversion' :extraversion,\n",
    "        'agreeableness' :agreeableness,\n",
    "        'neuroroticism' :neuroroticism\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bloque 4 \n",
    "import pandas as pd\n",
    "ruta_archivo_csv = 'DatasetConjunto.csv'\n",
    "texto = pd.read_csv(ruta_archivo_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texto 1:\n",
      "Hoy llegó mi nuevo escritorio, que ordené en línea hace dos semanas. Me dispuse a armarlo y organizar mis cosas, y fue un proceso muy sencillo siguiendo los pasos indicados en las instrucciones. Una ventaja adicional fue que incluía todas las herramientas necesarias para el armado.\n",
      "\n",
      "Puntuaciones de los cinco Grandes:\n",
      "openness: 0.99\n",
      "conscientiousness: 0.83\n",
      "extraversion: 0.17\n",
      "agreeableness: 0.97\n",
      "neuroroticism: 0.70\n"
     ]
    }
   ],
   "source": [
    "#Inserción del dataset para su evaluaciión \n",
    "for i, texto in enumerate (texto,1):\n",
    "    resultados = analizar_personalidad(texto)\n",
    "    print(f\"\\nTexto {i}:\\n{texto}\\n\")\n",
    "    print(\"Puntuaciones de los cinco Grandes:\")\n",
    "    for factor, puntuacion in resultados.items():\n",
    "        print(f\"{factor}: {puntuacion:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
