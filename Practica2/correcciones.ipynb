{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import math\n",
    "import operator\n",
    "import statistics\n",
    "from string import punctuation\n",
    "stop_words = set(stopwords.words('spanish') + list(punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_file(fname):\n",
    "    \"\"\"\n",
    "    Get file from text doc\n",
    "    \"\"\"\n",
    "    f=open(fname,'r')\n",
    "    text=f.readlines()\n",
    "    text=''.join(text) #converting the list to type str\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_five_txt_files(file_paths):\n",
    "  \"\"\"Reads the contents of five text files and returns a list of strings.\n",
    "  Args:\n",
    "    file_paths: A list of five file paths.\n",
    "  Returns:\n",
    "    A list of strings, where each string is the contents of one of the text files.\n",
    "  \"\"\"\n",
    "  texts = []\n",
    "  for file_path in file_paths:\n",
    "    with open(file_path, \"r\") as f:\n",
    "      texts.append(f.read())\n",
    "  return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_string_special_characters(s, convert_to_lower=True):\n",
    "    \"\"\"\n",
    "    This function removes special characters from within a string.\n",
    "    parameters: \n",
    "        s(str): single input string.\n",
    "    return: \n",
    "        stripped(str): A string with special characters removed.\n",
    "    \"\"\"\n",
    "\n",
    "    # Replace special character with ' '\n",
    "    stripped = re.sub('[^\\w\\s]', '', s)\n",
    "    stripped = re.sub('_', '', stripped)\n",
    "\n",
    "    # Change any whitespace to one space\n",
    "    stripped = re.sub('\\s+', ' ', stripped)\n",
    "    \n",
    "\n",
    "    # Remove start and end white spaces\n",
    "    stripped = stripped.strip()\n",
    "    if convert_to_lower:\n",
    "        stripped = stripped.lower()\n",
    "    \n",
    "    return stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"This function returns the \n",
    "    total number of words in the input text.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc(text_sents_clean):\n",
    "    \"\"\"\n",
    "    this function splits the text into sentences and\n",
    "    considering each sentence as a document, calculates the \n",
    "    total word count of each.\n",
    "    \"\"\"\n",
    "    doc_info = []\n",
    "    i = 0\n",
    "    for sent in text_sents_clean:\n",
    "        i += 1 \n",
    "        count = count_words(sent)\n",
    "        temp = {'doc_id' : i, 'doc_length' : count}\n",
    "        doc_info.append(temp)\n",
    "    return doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_dict(sents):\n",
    "    \"\"\"\n",
    "    This function creates a frequency dictionary\n",
    "    of each document that contains words other than\n",
    "    stop words.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    freqDict_list = []\n",
    "    for sent in sents:\n",
    "        i += 1\n",
    "        freq_dict = {}\n",
    "        words = word_tokenize(sent)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            if word not in stop_words:\n",
    "                if word in freq_dict:\n",
    "                    freq_dict[word] += 1\n",
    "                else:\n",
    "                    freq_dict[word] = 1\n",
    "                temp = {'doc_id' : i, 'freq_dict': freq_dict}\n",
    "        freqDict_list.append(temp)\n",
    "    return freqDict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_frequency(text_sents_clean):\n",
    "    \"\"\"\n",
    "    This function returns a dictionary with the frequency \n",
    "    count of every word in the text\n",
    "    \"\"\"\n",
    "    freq_table = {}\n",
    "    text = ' '.join(text_sents_clean) #join the cleaned sentences to get the text \n",
    "    words = word_tokenize(text)\n",
    "    for word in words:\n",
    "        word = word.lower()\n",
    "        if word not in stop_words:\n",
    "            if word in freq_table:\n",
    "                freq_table[word] += 1\n",
    "            else:\n",
    "                freq_table[word] = 1\n",
    "    return freq_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(text_sents_clean):\n",
    "    \"\"\"\n",
    "    This function gets the top 5 most\n",
    "    frequently occuring words in the whole text\n",
    "    and stores them as keywords\n",
    "    \"\"\"\n",
    "    freq_table = global_frequency(text_sents_clean)\n",
    "    #sort in descending order\n",
    "    freq_table_sorted = sorted(freq_table.items(), key = operator.itemgetter(1), reverse = True) \n",
    "    keywords = []\n",
    "    for i in range(0, 5):  #taking first 5 most frequent words\n",
    "        keywords.append(freq_table_sorted[i][0])\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(doc_info, freqDict_list):\n",
    "    \"\"\"\n",
    "    tf = (frequency of the term in the doc/total number of terms in the doc)\n",
    "    \"\"\"\n",
    "    TF_scores = []\n",
    "    \n",
    "    for tempDict in freqDict_list:\n",
    "        id = tempDict['doc_id']\n",
    "        for k in tempDict['freq_dict']:\n",
    "            temp = {'doc_id' : id,\n",
    "                    'TF_score' : tempDict['freq_dict'][k]/doc_info[id-1]['doc_length'],\n",
    "                   'key' : k}\n",
    "            TF_scores.append(temp)\n",
    "    return TF_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeIDF(doc_info, freqDict_list):\n",
    "    \"\"\"\n",
    "    idf = ln(total number of docs/number of docs with term in it)\n",
    "    \"\"\"\n",
    "    \n",
    "    IDF_scores = []\n",
    "    counter = 0\n",
    "    for dict in freqDict_list:\n",
    "        counter += 1\n",
    "        for k in dict['freq_dict'].keys():\n",
    "            count = sum([k in tempDict['freq_dict'] for tempDict in freqDict_list])\n",
    "            temp = {'doc_id' : counter, 'IDF_score' : math.log(len(doc_info)/count), 'key' : k}\n",
    "    \n",
    "            IDF_scores.append(temp)\n",
    "                \n",
    "    return IDF_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(TF_scores, IDF_scores):\n",
    "    \"\"\"\n",
    "    TFIDF is computed by multiplying the coressponding\n",
    "    TF and IDF values of each term. \n",
    "    \"\"\"\n",
    "    TFIDF_scores = []\n",
    "    for j in IDF_scores:\n",
    "        for i in TF_scores:\n",
    "            if j['key'] == i['key'] and j['doc_id'] == i['doc_id']:\n",
    "                temp = {'doc_id' : i['doc_id'],\n",
    "                        'TFIDF_score' : j['IDF_score']*i['TF_score'],\n",
    "                       'key' : i['key']}\n",
    "        TFIDF_scores.append(temp)\n",
    "    return TFIDF_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weigh_keywords(TFIDF_scores):\n",
    "    \"\"\"\n",
    "    This function doubles the TFIDF score\n",
    "    of the words that are keywords\n",
    "    \"\"\"\n",
    "    keywords = get_keywords(text_sents_clean)\n",
    "    for temp_dict in TFIDF_scores:\n",
    "        if temp_dict['key'] in keywords:\n",
    "            temp_dict['TFIDF_score'] *= 2\n",
    "    return TFIDF_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizador(texto):\n",
    "    oraciones= ['. ','\\n']\n",
    "    tokens = []\n",
    "\n",
    "    token_actual = ''\n",
    "    for caracter in texto:\n",
    "        #if caracter == ' ' or caracter in caracteres:\n",
    "        if caracter in oraciones:\n",
    "            if token_actual:\n",
    "                tokens.append(token_actual)\n",
    "                token_actual = ''\n",
    "        else:\n",
    "            token_actual += caracter\n",
    "\n",
    "    if token_actual:\n",
    "        tokens.append(token_actual)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_score(TFIDF_scores, text_sents, doc_info):\n",
    "    \"\"\"\n",
    "    This function prints out the summary and returns the \n",
    "    score of each sentence in a list.\n",
    "    \n",
    "    The score of a sentence is calculated by adding the TFIDF\n",
    "    scores of the words that make up the sentence.\n",
    "    \"\"\"\n",
    "    sentence_info = []\n",
    "    for doc in doc_info:\n",
    "        \"\"\"\n",
    "        This loops through each document(sentence)\n",
    "        and calculates their 'sent_score'\n",
    "        \"\"\"\n",
    "        sent_score = 0\n",
    "        for i in range(0, len(TFIDF_scores)):\n",
    "            temp_dict = TFIDF_scores[i]\n",
    "            if doc['doc_id'] == temp_dict['doc_id']:\n",
    "                sent_score += temp_dict['TFIDF_score']\n",
    "        temp = {'doc_id' : doc['doc_id'], 'sent_score' : sent_score,\n",
    "                'sentence' : text_sents[doc['doc_id']-1]}\n",
    "        sentence_info.append(temp)\n",
    "\n",
    "    return sentence_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_puntuacion_y_stopwords(texto):\n",
    "    # Eliminar signos de puntuación\n",
    "    texto_sin_puntuacion = \"\".join([caracter for caracter in texto if caracter not in string.punctuation])\n",
    "    # Tokenizar el texto\n",
    "    tokens = texto_sin_puntuacion.split()\n",
    "\n",
    "    \n",
    "    # Eliminar stopwords\n",
    "    stopwords_spanish = set(stopwords.words('spanish'))\n",
    "    tokens_sin_stopwords = [palabra for palabra in tokens if palabra.lower() not in stopwords_spanish]\n",
    "\n",
    "    # Unir las palabras nuevamente en una cadena de texto\n",
    "    texto_procesado = \" \".join(tokens_sin_stopwords)\n",
    "\n",
    "    return texto_procesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(sentence_info):\n",
    "    sum = 0\n",
    "    summary = []\n",
    "    array = []\n",
    "    for temp_dict in sentence_info:\n",
    "        \"\"\"\n",
    "        This loop gets the sum of scores\n",
    "        of all the sentences.\n",
    "        \"\"\"\n",
    "        sum += temp_dict['sent_score']\n",
    "    avg = sum/len(sentence_info) #computing the average tf-idf score\n",
    "    for temp_dict in sentence_info:\n",
    "        \"\"\"\n",
    "        This loop gets the sentence scores \n",
    "        and stores them in an array.\n",
    "        \"\"\"\n",
    "        array.append(temp_dict['sent_score'])\n",
    "    stdev = statistics.stdev(array) #computing standard deviation on the array   \n",
    "    for sent in sentence_info:\n",
    "        \"\"\"\n",
    "        This loop is for getting the sumamry by \n",
    "        extracting sentences by an if clause\n",
    "        \"\"\"\n",
    "        if(sent['sent_score']) >= avg: # + 1.5*stdev:\n",
    "            summary.append(sent['sentence'])\n",
    "    summary = '\\n'.join(summary)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: {'doc_id': 1, 'IDF_score': 1.6094379124341003, 'key': 'inteligencia'}\n",
      "Sentence 2: {'doc_id': 1, 'IDF_score': 1.6094379124341003, 'key': 'artificial'}\n",
      "Sentence 3: {'doc_id': 1, 'IDF_score': 2.0149030205422647, 'key': 'general'}\n",
      "Sentence 4: {'doc_id': 1, 'IDF_score': 2.70805020110221, 'key': 'agi'}\n",
      "Sentence 5: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'categoría'}\n",
      "Sentence 6: {'doc_id': 2, 'IDF_score': 1.6094379124341003, 'key': 'artificial'}\n",
      "Sentence 7: {'doc_id': 2, 'IDF_score': 2.0149030205422647, 'key': 'general'}\n",
      "Sentence 8: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'intelligence'}\n",
      "Sentence 9: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'alcanza'}\n",
      "Sentence 10: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'máquina'}\n",
      "Sentence 11: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'adquiere'}\n",
      "Sentence 12: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'capacidades'}\n",
      "Sentence 13: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'cognitivas'}\n",
      "Sentence 14: {'doc_id': 2, 'IDF_score': 2.0149030205422647, 'key': 'nivel'}\n",
      "Sentence 15: {'doc_id': 2, 'IDF_score': 2.70805020110221, 'key': 'humano'}\n",
      "Sentence 16: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'decir'}\n",
      "Sentence 17: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'puede'}\n",
      "Sentence 18: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'realizar'}\n",
      "Sentence 19: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'cualquier'}\n",
      "Sentence 20: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'tarea'}\n",
      "Sentence 21: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'intelectual'}\n",
      "Sentence 22: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'realiza'}\n",
      "Sentence 23: {'doc_id': 3, 'IDF_score': 2.70805020110221, 'key': 'persona'}\n",
      "Sentence 24: {'doc_id': 4, 'IDF_score': 2.70805020110221, 'key': 'conoce'}\n",
      "Sentence 25: {'doc_id': 4, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 26: {'doc_id': 4, 'IDF_score': 2.70805020110221, 'key': 'fuerte'}\n",
      "Sentence 27: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'tal'}\n",
      "Sentence 28: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'creencia'}\n",
      "Sentence 29: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'borde'}\n",
      "Sentence 30: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'alcanzar'}\n",
      "Sentence 31: {'doc_id': 5, 'IDF_score': 2.0149030205422647, 'key': 'nivel'}\n",
      "Sentence 32: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'desarrollo'}\n",
      "Sentence 33: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'marzo'}\n",
      "Sentence 34: {'doc_id': 5, 'IDF_score': 2.0149030205422647, 'key': 'pasado'}\n",
      "Sentence 35: {'doc_id': 5, 'IDF_score': 2.0149030205422647, 'key': '1000'}\n",
      "Sentence 36: {'doc_id': 5, 'IDF_score': 1.0986122886681098, 'key': 'expertos'}\n",
      "Sentence 37: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'tecnología'}\n",
      "Sentence 38: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'pidieron'}\n",
      "Sentence 39: {'doc_id': 5, 'IDF_score': 1.6094379124341003, 'key': 'empresas'}\n",
      "Sentence 40: {'doc_id': 5, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 41: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'dejen'}\n",
      "Sentence 42: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'entrenar'}\n",
      "Sentence 43: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'menos'}\n",
      "Sentence 44: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'seis'}\n",
      "Sentence 45: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'meses'}\n",
      "Sentence 46: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'aquellos'}\n",
      "Sentence 47: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'programas'}\n",
      "Sentence 48: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'poderosos'}\n",
      "Sentence 49: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'gpt4'}\n",
      "Sentence 50: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'versión'}\n",
      "Sentence 51: {'doc_id': 5, 'IDF_score': 2.70805020110221, 'key': 'reciente'}\n",
      "Sentence 52: {'doc_id': 5, 'IDF_score': 2.0149030205422647, 'key': 'chatgpt'}\n",
      "Sentence 53: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'sistemas'}\n",
      "Sentence 54: {'doc_id': 6, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 55: {'doc_id': 6, 'IDF_score': 1.6094379124341003, 'key': 'inteligencia'}\n",
      "Sentence 56: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'compite'}\n",
      "Sentence 57: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'humana'}\n",
      "Sentence 58: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'pueden'}\n",
      "Sentence 59: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'plantear'}\n",
      "Sentence 60: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'profundos'}\n",
      "Sentence 61: {'doc_id': 6, 'IDF_score': 2.0149030205422647, 'key': 'riesgos'}\n",
      "Sentence 62: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'sociedad'}\n",
      "Sentence 63: {'doc_id': 6, 'IDF_score': 2.0149030205422647, 'key': 'humanidad'}\n",
      "Sentence 64: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'advirtieron'}\n",
      "Sentence 65: {'doc_id': 6, 'IDF_score': 1.3217558399823195, 'key': 'carta'}\n",
      "Sentence 66: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'abierta'}\n",
      "Sentence 67: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'cofundador'}\n",
      "Sentence 68: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'apple'}\n",
      "Sentence 69: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'steve'}\n",
      "Sentence 70: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'wozniak'}\n",
      "Sentence 71: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'dueño'}\n",
      "Sentence 72: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'tesla'}\n",
      "Sentence 73: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'spacex'}\n",
      "Sentence 74: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'neuralink'}\n",
      "Sentence 75: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'twitter'}\n",
      "Sentence 76: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'elon'}\n",
      "Sentence 77: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'musk'}\n",
      "Sentence 78: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'cofundadores'}\n",
      "Sentence 79: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'open'}\n",
      "Sentence 80: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'ai'}\n",
      "Sentence 81: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'renunciar'}\n",
      "Sentence 82: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'junta'}\n",
      "Sentence 83: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'desacuerdos'}\n",
      "Sentence 84: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'conducción'}\n",
      "Sentence 85: {'doc_id': 6, 'IDF_score': 2.70805020110221, 'key': 'compañía'}\n",
      "Sentence 86: {'doc_id': 7, 'IDF_score': 1.3217558399823195, 'key': 'carta'}\n",
      "Sentence 87: {'doc_id': 7, 'IDF_score': 2.0149030205422647, 'key': '1000'}\n",
      "Sentence 88: {'doc_id': 7, 'IDF_score': 1.0986122886681098, 'key': 'expertos'}\n",
      "Sentence 89: {'doc_id': 7, 'IDF_score': 2.70805020110221, 'key': 'piden'}\n",
      "Sentence 90: {'doc_id': 7, 'IDF_score': 2.0149030205422647, 'key': 'frenar'}\n",
      "Sentence 91: {'doc_id': 7, 'IDF_score': 1.6094379124341003, 'key': 'inteligencia'}\n",
      "Sentence 92: {'doc_id': 7, 'IDF_score': 1.6094379124341003, 'key': 'artificial'}\n",
      "Sentence 93: {'doc_id': 7, 'IDF_score': 2.0149030205422647, 'key': 'ser'}\n",
      "Sentence 94: {'doc_id': 7, 'IDF_score': 2.70805020110221, 'key': 'amenaza'}\n",
      "Sentence 95: {'doc_id': 7, 'IDF_score': 2.0149030205422647, 'key': 'humanidad'}\n",
      "Sentence 96: {'doc_id': 8, 'IDF_score': 1.3217558399823195, 'key': 'carta'}\n",
      "Sentence 97: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'publicada'}\n",
      "Sentence 98: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'organización'}\n",
      "Sentence 99: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'fines'}\n",
      "Sentence 100: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'lucro'}\n",
      "Sentence 101: {'doc_id': 8, 'IDF_score': 2.0149030205422647, 'key': 'future'}\n",
      "Sentence 102: {'doc_id': 8, 'IDF_score': 2.0149030205422647, 'key': 'of'}\n",
      "Sentence 103: {'doc_id': 8, 'IDF_score': 2.0149030205422647, 'key': 'life'}\n",
      "Sentence 104: {'doc_id': 8, 'IDF_score': 2.0149030205422647, 'key': 'institute'}\n",
      "Sentence 105: {'doc_id': 8, 'IDF_score': 1.0986122886681098, 'key': 'expertos'}\n",
      "Sentence 106: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'dijeron'}\n",
      "Sentence 107: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'si'}\n",
      "Sentence 108: {'doc_id': 8, 'IDF_score': 1.6094379124341003, 'key': 'empresas'}\n",
      "Sentence 109: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'acceden'}\n",
      "Sentence 110: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'rápidamente'}\n",
      "Sentence 111: {'doc_id': 8, 'IDF_score': 2.0149030205422647, 'key': 'frenar'}\n",
      "Sentence 112: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'proyectos'}\n",
      "Sentence 113: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'gobiernos'}\n",
      "Sentence 114: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'deberían'}\n",
      "Sentence 115: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'intervenir'}\n",
      "Sentence 116: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'instituir'}\n",
      "Sentence 117: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'moratoria'}\n",
      "Sentence 118: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'puedan'}\n",
      "Sentence 119: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'diseñar'}\n",
      "Sentence 120: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'implementar'}\n",
      "Sentence 121: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'medidas'}\n",
      "Sentence 122: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'seguridad'}\n",
      "Sentence 123: {'doc_id': 8, 'IDF_score': 2.70805020110221, 'key': 'sólidas'}\n",
      "Sentence 124: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'aunque'}\n",
      "Sentence 125: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'momento'}\n",
      "Sentence 126: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'ocurrido'}\n",
      "Sentence 127: {'doc_id': 9, 'IDF_score': 2.0149030205422647, 'key': 'gobierno'}\n",
      "Sentence 128: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'unidos'}\n",
      "Sentence 129: {'doc_id': 9, 'IDF_score': 2.0149030205422647, 'key': 'convocó'}\n",
      "Sentence 130: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'dueños'}\n",
      "Sentence 131: {'doc_id': 9, 'IDF_score': 2.0149030205422647, 'key': 'principales'}\n",
      "Sentence 132: {'doc_id': 9, 'IDF_score': 1.6094379124341003, 'key': 'empresas'}\n",
      "Sentence 133: {'doc_id': 9, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 134: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'alphabet'}\n",
      "Sentence 135: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'anthropic'}\n",
      "Sentence 136: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'microsoft'}\n",
      "Sentence 137: {'doc_id': 9, 'IDF_score': 2.0149030205422647, 'key': 'openai'}\n",
      "Sentence 138: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'acordar'}\n",
      "Sentence 139: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'nuevas'}\n",
      "Sentence 140: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'acciones'}\n",
      "Sentence 141: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'promover'}\n",
      "Sentence 142: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'innovación'}\n",
      "Sentence 143: {'doc_id': 9, 'IDF_score': 2.70805020110221, 'key': 'responsable'}\n",
      "Sentence 144: {'doc_id': 10, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 145: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'tecnologías'}\n",
      "Sentence 146: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'poderosas'}\n",
      "Sentence 147: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'tiempo'}\n",
      "Sentence 148: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'aprovechar'}\n",
      "Sentence 149: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'oportunidades'}\n",
      "Sentence 150: {'doc_id': 10, 'IDF_score': 2.0149030205422647, 'key': 'presenta'}\n",
      "Sentence 151: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'primero'}\n",
      "Sentence 152: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'debemos'}\n",
      "Sentence 153: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'mitigar'}\n",
      "Sentence 154: {'doc_id': 10, 'IDF_score': 2.0149030205422647, 'key': 'riesgos'}\n",
      "Sentence 155: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'declaró'}\n",
      "Sentence 156: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'través'}\n",
      "Sentence 157: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'comunicado'}\n",
      "Sentence 158: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'casa'}\n",
      "Sentence 159: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'blanca'}\n",
      "Sentence 160: {'doc_id': 10, 'IDF_score': 2.0149030205422647, 'key': 'pasado'}\n",
      "Sentence 161: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': '4'}\n",
      "Sentence 162: {'doc_id': 10, 'IDF_score': 2.70805020110221, 'key': 'mayo'}\n",
      "Sentence 163: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'congreso'}\n",
      "Sentence 164: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'eeuu'}\n",
      "Sentence 165: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'parte'}\n",
      "Sentence 166: {'doc_id': 11, 'IDF_score': 2.0149030205422647, 'key': 'convocó'}\n",
      "Sentence 167: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'martes'}\n",
      "Sentence 168: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'ceo'}\n",
      "Sentence 169: {'doc_id': 11, 'IDF_score': 2.0149030205422647, 'key': 'openai'}\n",
      "Sentence 170: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'sam'}\n",
      "Sentence 171: {'doc_id': 11, 'IDF_score': 2.0149030205422647, 'key': 'altman'}\n",
      "Sentence 172: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'responder'}\n",
      "Sentence 173: {'doc_id': 11, 'IDF_score': 2.70805020110221, 'key': 'preguntas'}\n",
      "Sentence 174: {'doc_id': 11, 'IDF_score': 2.0149030205422647, 'key': 'chatgpt'}\n",
      "Sentence 175: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'audiencia'}\n",
      "Sentence 176: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'senado'}\n",
      "Sentence 177: {'doc_id': 12, 'IDF_score': 2.0149030205422647, 'key': 'altman'}\n",
      "Sentence 178: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'dijo'}\n",
      "Sentence 179: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'crucial'}\n",
      "Sentence 180: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'industria'}\n",
      "Sentence 181: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'regulada'}\n",
      "Sentence 182: {'doc_id': 12, 'IDF_score': 2.0149030205422647, 'key': 'gobierno'}\n",
      "Sentence 183: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'medida'}\n",
      "Sentence 184: {'doc_id': 12, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 185: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'vuelve'}\n",
      "Sentence 186: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'cada'}\n",
      "Sentence 187: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'vez'}\n",
      "Sentence 188: {'doc_id': 12, 'IDF_score': 2.70805020110221, 'key': 'poderosa'}\n",
      "Sentence 189: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'carlos'}\n",
      "Sentence 190: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'ignacio'}\n",
      "Sentence 191: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'gutiérrez'}\n",
      "Sentence 192: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'investigador'}\n",
      "Sentence 193: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'políticas'}\n",
      "Sentence 194: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'públicas'}\n",
      "Sentence 195: {'doc_id': 13, 'IDF_score': 2.0149030205422647, 'key': 'future'}\n",
      "Sentence 196: {'doc_id': 13, 'IDF_score': 2.0149030205422647, 'key': 'of'}\n",
      "Sentence 197: {'doc_id': 13, 'IDF_score': 2.0149030205422647, 'key': 'life'}\n",
      "Sentence 198: {'doc_id': 13, 'IDF_score': 2.0149030205422647, 'key': 'institute'}\n",
      "Sentence 199: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'explicó'}\n",
      "Sentence 200: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'bbc'}\n",
      "Sentence 201: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'mundo'}\n",
      "Sentence 202: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'grandes'}\n",
      "Sentence 203: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'desafíos'}\n",
      "Sentence 204: {'doc_id': 13, 'IDF_score': 2.0149030205422647, 'key': 'presenta'}\n",
      "Sentence 205: {'doc_id': 13, 'IDF_score': 0.7621400520468967, 'key': 'ia'}\n",
      "Sentence 206: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'existe'}\n",
      "Sentence 207: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'cuerpo'}\n",
      "Sentence 208: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'colegiado'}\n",
      "Sentence 209: {'doc_id': 13, 'IDF_score': 1.0986122886681098, 'key': 'expertos'}\n",
      "Sentence 210: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'deciden'}\n",
      "Sentence 211: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'cómo'}\n",
      "Sentence 212: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'regularlo'}\n",
      "Sentence 213: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'ocurre'}\n",
      "Sentence 214: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'ejemplo'}\n",
      "Sentence 215: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'panel'}\n",
      "Sentence 216: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'intergubernamental'}\n",
      "Sentence 217: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'cambio'}\n",
      "Sentence 218: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'climático'}\n",
      "Sentence 219: {'doc_id': 13, 'IDF_score': 2.70805020110221, 'key': 'ipcc'}\n",
      "Sentence 220: {'doc_id': 14, 'IDF_score': 1.3217558399823195, 'key': 'carta'}\n",
      "Sentence 221: {'doc_id': 14, 'IDF_score': 1.0986122886681098, 'key': 'expertos'}\n",
      "Sentence 222: {'doc_id': 14, 'IDF_score': 2.70805020110221, 'key': 'definieron'}\n",
      "Sentence 223: {'doc_id': 14, 'IDF_score': 2.70805020110221, 'key': 'cuáles'}\n",
      "Sentence 224: {'doc_id': 14, 'IDF_score': 2.0149030205422647, 'key': 'principales'}\n",
      "Sentence 225: {'doc_id': 14, 'IDF_score': 2.70805020110221, 'key': 'preocupaciones'}\n",
      "Sentence 226: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'deberíamos'}\n",
      "Sentence 227: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'desarrollar'}\n",
      "Sentence 228: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'mentes'}\n",
      "Sentence 229: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'humanas'}\n",
      "Sentence 230: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'eventualmente'}\n",
      "Sentence 231: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'podrían'}\n",
      "Sentence 232: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'superarnos'}\n",
      "Sentence 233: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'número'}\n",
      "Sentence 234: {'doc_id': 15, 'IDF_score': 2.0149030205422647, 'key': 'ser'}\n",
      "Sentence 235: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'inteligentes'}\n",
      "Sentence 236: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'hacernos'}\n",
      "Sentence 237: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'obsoletos'}\n",
      "Sentence 238: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'reemplazarnos'}\n",
      "Sentence 239: {'doc_id': 15, 'IDF_score': 2.70805020110221, 'key': 'cuestionaron'}\n",
      "Inteligencia artificial general (AGI)\n",
      "Esta categoría -Artificial General Intelligence- se alcanza cuando una máquina adquiere capacidades cognitivas a nivel humano.\n",
      "Es decir, cuando puede realizar cualquier tarea intelectual que realiza una persona.\n",
      "Carlos Ignacio Gutiérrez, investigador de políticas públicas en el Future of Life Institute, explicó a BBC Mundo que uno de los grandes desafíos que presenta la IA es que \"no existe un cuerpo colegiado de expertos que deciden cómo regularlo, como ocurre, por ejemplo, con el Panel Intergubernamental sobre Cambio Climático (IPCC)\".\n",
      "\"¿Deberíamos desarrollar mentes no humanas que eventualmente podrían superarnos en número, ser más inteligentes, hacernos obsoletos y reemplazarnos?\", cuestionaron.\n"
     ]
    }
   ],
   "source": [
    "with open('prueba2_ia.txt', 'r', encoding='utf-8') as file:\n",
    "    texto = file.read()\n",
    "\n",
    "oraciones = tokenizador(texto)\n",
    "#oraciones = sent_tokenize(text)\n",
    "\n",
    "oraciones_lim = [remove_string_special_characters(s) for s in oraciones]#Se va ingresando por oración \n",
    "#for i in range(len(oraciones_lim)):\n",
    "#    print(\"Sentence {}: {}\".format(i+1, oraciones_lim[i]))\n",
    "\n",
    "doc_info = get_doc(oraciones_lim) # Se encarga  de odtener la longitud de cada uno de las oraciones eliminando las Stopwords\n",
    "#for i in range(len(oraciones_lim)):\n",
    "#    print(\"Sentence {}: {}\".format(i+1, doc_info[i]))\n",
    "\n",
    "freqDict_list = create_freq_dict(oraciones_lim)\n",
    "#for i in range(len(oraciones_lim)):\n",
    "#    print(\"Sentence {}: {}\".format(i+1, freqDict_list[i]))\n",
    "TF_scores = computeTF(doc_info, freqDict_list)\n",
    "#for i in range(len(TF_scores)):\n",
    "#    print(\"Sentence {}: {}\".format(i+1, TF_scores[i]))\n",
    "IDF_scores = computeIDF(doc_info, freqDict_list)\n",
    "for i in range(len(IDF_scores)):\n",
    "    print(\"Sentence {}: {}\".format(i+1, IDF_scores[i]))\n",
    "\n",
    "TFIDF_scores = computeTFIDF(TF_scores, IDF_scores)\n",
    "TFIDF_scores = weigh_keywords(TFIDF_scores)\n",
    "sentence_info = get_sent_score(TFIDF_scores, oraciones, doc_info)\n",
    "\n",
    "doc_info = get_doc(oraciones_lim)\n",
    "summary = get_summary(sentence_info)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
